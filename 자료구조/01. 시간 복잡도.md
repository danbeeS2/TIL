# 1. 시간 복잡도 (Time Complexity)

![시간복잡도](/자료구조/images/time_complexity.png)

## 1) 표기법 (Notation)
> 알고리즘과 자료구조의 성능을 수학적으로 표현할 때 사용하는 표기법

- **Big-O (O)**: **최악의 경우**
- **Big-Theta (θ)**: 최악의 경우 == 최선의 경우 
- **Big-Omega (Ω)**: 최선의 경우

> #### ex. `[1, 2, 3, 4, 5]`
>
> - 3번째의 값을 찾기 →  작업량: 1
> - 값 4를 찾기 → 작업량: 4 (1번째부터 탐색)
>   - 최악의 경우: `[1, 2, 3, 5, 4]` → 작업량: 5 (배열의 길이 n) → `O(n)`
>
>   - 최선의 경우: `[4, 1, 2, 3, 5]` → 작업량: 1 → `Ω(1)`
> 
>   - `θ`는 없음 → `O(n) ≠ Ω(1)`

### 최선의 경우보다는 '최악의 경우 `Big-O`'를 더 많이 쓴다!
현실에서는 '최선의 경우'보다 **'최악의 경우'** 를 더 많이 마주하게 된다.  
최선은 단 한 번 만에 성공하는 경우이지만, 실제로는 그렇지 않은 경우가 대부분이기 때문이다.    
또한 **최악의 경우에는 작업량이 급증할 수 있기 때문에** 우리는 그런 상황을 피하기 위해서 항상 최악의 경우를 더욱 주의깊게 봐야 한다.  


## 2) 시간 복잡도 등급
⇒ 어떤 자료구조 / 알고리즘이 효율적인지를 판단할 때, `Big-O` 표기법 사용
- `O(1)` : 제일 좋은 알고리즘 ⇒ 최선 (상수)
- `O(log n)` 
- `O(n)`
- `O(n log n)` : 이정도면 훌륭하다
- `O(n²)` : 실무에서의 마지노선
---
- `O(n³)` : 아주 나쁜 경우지만, 괜찮다. (일반적으로 비효율적이나 때때로 허용)
- `O(2ⁿ)` : 적극적으로 피하라
- `O(n!)` : 적극적으로 피하라

 ✅ `Big-O`는 (바보 알고리즘이 아니라) **이미 최선의 알고리즘을 사용했음에도 불구하고** 생길 수 있는 **최악의 경우**를 말함  
> 

> #### ex. 업다운 게임  `[1, ...  50, ... 100]`  
> - `O(n)` : 1부터 100까지 하나씩 비교하는 순차 탐색 (바보 알고리즘)    
> - `O(log n)` : 50부터 시작해 절반씩 줄여가는 이진 탐색 (최악의 경우)   


## 3) 코드 상 시간 복잡도
- `O(n)` : for문 - `for (i++)`
- `O(n²)` : 이중 for문 - `for (i++)` +  `for (j++)` 
- `O(n³)` : 삼중 for문  - `for (i++)` +  `for (j++)` + `for (k++)` 

  ---
- `O(log n)` : `for (i *= 2)` 
    - i가 순차적으로 증감하는 것이 아니라 곱하기 나누기 등으로 점프
- `O(n log n)` : `for (i++)` +  `for (j *= 2)`   

✅ 반복문의 **중첩 횟수**와 증감 방식에 따라 복잡도가 달라짐

## 4) 시간 복잡도 vs 공간 복잡도
- 시간 복잡도 (Time Complexity): 시간이 얼마나 오래 걸렸나
- 공간 복잡도 (Space Complexity): 메모리를 얼마나 많이 차지하나
    - `O(n)`, `O(2n)` 정도 있으나, 실제로 잘 따지지는 않는다


## 5) O(n) vs O(2n) vs O(n²)
- `O(2n)`은 `O(n)`과 **동일한 수준**으로 간주 (계수는 무시)
- 하지만 `O(n²)`은 `O(n)`에 비해 **차원이 다른 성능 차이**를 보임 (수가 커질수록 더 큰 차이) 
    - ex. n = 100 → `O(n)` = 100, `O(n²)` = 10,000   

 ✅ **계수보다는 지수에 신경을 써야 함**  
    지수는 `반복문의 중첩 횟수`와 밀접하게 관련됨


